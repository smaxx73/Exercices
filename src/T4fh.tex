\uuid{T4fh}
\titre{Estimateurs et loi de Bernoulli}
\theme{probabilité}
\auteur{}
\organisation{AMSCC}
\contenu{

Soit $X$ une variable aléatoire suivant une loi de Bernoulli $\mathcal{B}(p)$ où $p \in ]0;1[$. On considère un $n$-échantillon de $X$ et on note $\overline{X}$ sa moyenne empirique. On pose $Y = n\overline{X}$. 

\begin{enumerate}
	\item \question{ Exprimer $\mathbb{E}(Y)$ et $\mathbb{E}(Y^2)$ en fonction de $n$ et $p$. }
	\reponse{ On considère $Y = n\overline{X} = \sum_{i=1}^n X_i$ : par définition, $Y$ suit une loi binomiale $\mathcal{B}(n,p)$, ce qui permet d'affirmer que $\mathbb{E}(Y) = np$ et $V(Y) = np(1-p)$. Or on sait que $V(Y) = \mathbb{E}(Y^2)-(\mathbb{E}(Y))^2$, donc $\mathbb{E}(Y^2) = np(1-p)+(np)^2 = np(1+p(n-1))$ }
	\item \question{ On pose $Z = \overline{X}^2$. Peut-on dire que $Z$ est un estimateur sais biais de $p^2$ ? }
	\reponse{ En voyant la variable $Z$ comme un estimateur de $p^2$, on va calculer son biais $B(Z)=\mathbb{E}(Z-p^2) = \mathbb{E}(Z)-p^2$. Or $\mathbb{E}(Z) = \mathbb{E}\left(\left(\frac{1}{n}Y\right)^2\right) = \frac{1}{n^2}\mathbb{E}(Y^2) = \frac{p}{n} + p^2 \frac{n-1}{n} \neq p^2$ donc $B(Z) \neq 0$. }
	\item \question{ On pose $T = \frac{Y(Y-1)}{n(n-1)}$. Vérifier que $T$ est un estimateur sans biais de $p^2$.  }
	\reponse{ En revanche, $\mathbb{E}(T) = \frac{1}{n(n-1)}\mathbb{E}(Y(Y-1)) = \frac{1}{n(n-1)}(np(1+(n-1)p)-np) = p^2$ donc $T$ est un estimateur non biaisé de la valeur $p^2$. }
\end{enumerate}
}
