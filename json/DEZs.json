{
  "uuid": "DEZs",
  "titre": "Estimateur et intervalle de confiance",
  "theme": "probabilités",
  "auteur": "",
  "date": "",
  "organisation": "AMSCC",
  "contenu": [
    {
      "type": "texte",
      "value": "Soient $X_1,...,X_n$ des variables aléatoires indépendantes et de même loi ayant pour densité :\n\t$$f_\\theta \\colon x \\mapsto \\left\\{\n\t\\begin{array}{ll}\n\t\t\\frac{1}{2}(1+\\theta x) & \\mbox{si } -1 \\leq x \\leq 1 \\\\\n\t\t0 & \\mbox{sinon.}\n\t\\end{array}\n\t\\right.$$\n\toù $\\theta \\in [-1;1]$ est un paramètre."
    },
    {
      "type": "question",
      "value": "Montrer que pour tout $\\theta \\in [-1;1]$, $f_\\theta $ est une densité de probabilité."
    },
    {
      "type": "reponse",
      "value": "Le fait que $\\theta \\in [-1;1]$ garantit que $f_{\\theta}(x) \\geq 0$ pour tout $x \\in [-1;1]$. De plus, \n\t\t$$\\begin{align*}\n\t\t\t\\int f_\\theta(x) dx &= \\int_{-1}^{1} \\frac{1}{2}(1+\\theta x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(1+0) dx \\quad \\text{ par imparité de x} \\\\\n\t\t\t&= 1\n\t\t\\end{align*}$$\t\n\t\tDonc $f_{\\theta}$ définit une bien une densité de probabilité."
    },
    {
      "type": "question",
      "value": "Calculer $\\mathbb{E}(X_1)$ et $\\mathbb{V}(X_1)$. En déduire l'espérance et la variance de la variable aléatoire $\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$."
    },
    {
      "type": "reponse",
      "value": "On calcule les moments d'ordre 1 et 2 de la variable à densité $X_1$ :\n\t\t$$\\begin{align*}\n\t\t\t\\mathbb{E}(X_1) &= \\int x f_\\theta(x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x+\\theta x^2) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par imparité de $x$} \\\\\n\t\t\t&= 2\\int_{0}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par parité de $x^2$} \\\\\n\t\t\t&= \\frac{\\theta}{3}\n\t\t\\end{align*}$$\n\t\tDe même, \t\t\n\t\t$$\\begin{align*}\n\t\t\t\\mathbb{E}(X_1^2) &= \\int x^2 f_\\theta(x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x^2+\\theta x^3) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x^2) dx \\quad \\text{ par imparité de $x^3$} \\\\\n\t\t\t&= \\int_{0}^{1}  x^2 dx \\quad \\text{ par parité de $x^2$} \\\\\n\t\t\t&= \\frac{1}{3}\n\t\t\\end{align*}$$\n\t\t\n\t\tAvec la formule de Koenig Huygens, on en déduit que \n\t\t$$\\mathbb{V}(X_1) = \\mathbb{E}(X_1^2) - \t\\mathbb{E}(X_1)^2 = \\frac{1}{3}-\\frac{\\theta^2}{9} = \\frac{3-\\theta^2}{9}$$"
    },
    {
      "type": "question",
      "value": "On pose $T_n = \\frac{3}{n} \\sum_{i=1}^{n} X_i$. Montrer que $T$ est un estimateur sans biais et convergent de $\\theta$."
    },
    {
      "type": "reponse",
      "value": "On calcule par linéarité de l'espérance : $\\mathbb{E}(T_n) = \\frac{3}{n} \\times n \\mathbb{E}(X_1) = \\theta$. Donc le biais de $T_n$ est \n\t\t$B(T_n) = \\mathbb{E}(T_n-\\theta) =\\theta - \\theta = 0$.\n\t\t\n\t\tDe plus, par propriétés de la variance et indépendance, \n\t\t$$\\mathbb{V}(T_n) =  \\frac{9}{n^2} \\times n \\times \\mathbb{V}(X_1) = \\frac{3-\\theta^2}{n}$$\n\t\tOr $EQM(T_n) = \\mathbb{V}(T_n) + B(T_n)^2$ donc $EQM(T_n) = \\frac{3-\\theta^2}{n} \\xrightarrow[n \\to +\\infty]{} 0$ : cela prouve que l'estimateur $T_n$ est convergent."
    },
    {
      "type": "question",
      "value": "\\`A l'aide du Théorème Central Limite, donner une approximation de la loi de $T_n$."
    },
    {
      "type": "reponse",
      "value": "On pose $\\mu = \\mathbb{E}(X_1)$ et $\\sigma = \\sqrt{\\mathbb{V}(X_1)}$. Les variables $(X_i)$ sont iid, admettent une espérance et une variance donc d'après le théorème central limite, la variable \n\t\t$$\\frac{\\sum_{i=1}^n X_i - n\\mu}{\\sigma\\sqrt{n} }$$ converge en loi vers une loi normale $\\mathcal{N}(0,1)$.\n\t\tEn réécrivant, cela revient à dire que \t\n\t\t$$\\frac{\\frac{3}{n}\\sum_{i=1}^n X_i - 3\\mu}{3\\frac{\\sigma}{\\sqrt{n}} } = \\frac{T_n-\\theta}{\\sqrt{\\frac{3-\\theta^2}{n}}}$$ converge en loi vers une loi normale $\\mathcal{N}(0,1)$.\n\t\t\n\t\tSi $n$ est grand ($n \\geq 30$), cela revient à dire que $T_n$ suit approximativement une loi normale $\\mathcal{N}(\\theta, \\sigma^2 = \\frac{3-\\theta^2}{n})$."
    },
    {
      "type": "question",
      "value": "Démontrer qu'il existe une constante $M_n$ ne dépendant pas de $\\theta$ telle que si $\\lambda >0$, \n\t\t$$\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{M_n}{\\lambda^2}$$"
    },
    {
      "type": "reponse",
      "value": "D'après l'inégalité de Bienaymé Tchebichev, \n\t\t$$\\PP(|T_n-\\mathbb{E}(T_n)| \\geq  \\lambda) \\leq \\frac{\\mathbb{V}(T_n)}{\\lambda^2}$$\n\t\td'où $$\\PP(|T_n-\\theta| \\geq \\lambda) \\leq \\frac{3-\\theta^2}{n\\lambda^2} \\leq \\frac{3}{n\\lambda^2} = \\frac{M_n}{\\lambda^2}$$\n\t\ten posant $M_n = \\frac{3}{n}$.  Par passage au complémentaire, on obtient finalement :\n\t\t$$\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{3}{n\\lambda^2}$$"
    },
    {
      "type": "question",
      "value": "Déterminer un intervalle de  confiance permettant d'estimer $\\theta$ avec une confiance d'au moins $95\\%$."
    },
    {
      "type": "reponse",
      "value": "On cherche un intervalle $I$ tel que $\\PP(\\theta \\in I) \\geq 0{,}95$. Or d'après ce qui précède,\n\t\t\n\t\t$$\\begin{align*}\n\t\t\t\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{3}{n\\lambda^2} &\\iff \\PP(-\\lambda < T_n-\\theta < \\lambda ) \\geq 1-\\frac{3}{n\\lambda^2} \\\\\n\t\t\t&\\iff\t\\PP( \\theta \\in ]T_n-\\lambda ; T_n + \\lambda [) \\geq 1-\\frac{3}{n\\lambda^2} \t\n\t\t\\end{align*}$$ \n\t\tOr \t$1-\\frac{3}{n\\lambda^2} = 0{,}95 \\iff \\frac{3}{n\\lambda^2} = 0{,}05 \\iff \\lambda^2 = \\frac{3}{0{,}05 n}$\n\t\tdonc \n\t\t$$\\PP\\left( \\theta \\in \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[\\right) \\geq 0{,}95$$\n\t\td'où l'intervalle de confiance $I = \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[$."
    }
  ]
}