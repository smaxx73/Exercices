{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3: Classification de texte (exemple : détection de spam)\n",
    "\n",
    "Dans ce notebook, nous allons :\n",
    "1. Charger un jeu de données textuelles (spam vs ham).\n",
    "2. Appliquer un prétraitement léger (optionnel).\n",
    "3. Utiliser une **représentation vectorielle** (TF-IDF).\n",
    "4. Entraîner un **modèle de classification** (Naive Bayes).\n",
    "5. Évaluer les performances via des métriques (accuracy, matrice de confusion, rapport de classification).\n",
    "\n",
    "Nous allons utiliser les bibliothèques suivantes :\n",
    "- **pandas** pour la manipulation des données,\n",
    "- **scikit-learn** pour la classification et l'évaluation,\n",
    "- éventuellement **nltk** si nous faisons un prétraitement (tokenisation, stopwords, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 1. Import des bibliothèques\n",
    "# ========================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Optionnel) NLTK pour un prétraitement plus poussé\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import PorterStemmer, WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chargement des données\n",
    "\n",
    "Dans un cas réel, vous pouvez disposer d'un fichier `spam_data.csv` ou utiliser un dataset\n",
    "existant (comme [SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)).\n",
    "\n",
    "Pour la démonstration, nous allons créer un petit dataset factice avec deux colonnes :\n",
    "- `text` : le contenu du message\n",
    "- `label` : \"spam\" ou \"ham\" (message légitime).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 2. Création d'un petit DataFrame d'exemple\n",
    "# ========================================================================\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"WINNER!! This is the secret code to claim your prize: 1234\",\n",
    "        \"Hello John, how about a movie tonight?\",\n",
    "        \"Earn $1000 per day!!! Exclusive offer, click now.\",\n",
    "        \"Reminder: meeting tomorrow at 10am. Don't be late!\",\n",
    "        \"Urgent!!! Your account is compromised, click here to secure now\",\n",
    "        \"Hey buddy, long time no see. Let's catch up soon?\",\n",
    "        \"Congratulations, you've been selected for a free gift card!\",\n",
    "        \"Are you available for lunch tomorrow?\",\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"spam\",\n",
    "        \"ham\",\n",
    "        \"spam\",\n",
    "        \"ham\",\n",
    "        \"spam\",\n",
    "        \"ham\",\n",
    "        \"spam\",\n",
    "        \"ham\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez voir un mini-tableau avec des messages et leur label.\n",
    "\n",
    "---\n",
    "# 3. (Optionnel) Prétraitement du texte\n",
    "\n",
    "Il est souvent utile (voir le notebook précédent) de normaliser et nettoyer les textes :  \n",
    "- passer en minuscules,  \n",
    "- supprimer la ponctuation, les nombres, etc.,  \n",
    "- éventuellement tokeniser et supprimer les stopwords.\n",
    "\n",
    "Ici, nous allons faire une version **simplifiée** : passage en minuscules et retrait de ponctuation de base, pour illustrer la démarche.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def simple_preprocess(text):\n",
    "    text = text.lower()\n",
    "    # Retirer les caractères de ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Supprimer les chiffres (optionnel)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Supprimer les espaces multiples\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(simple_preprocess)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez constater dans la colonne `cleaned_text` que le texte est un peu plus standardisé.\n",
    "\n",
    "---\n",
    "# 4. Séparation en jeu d'entraînement et de test\n",
    "\n",
    "Nous séparons notre dataset en deux parties :\n",
    "- un ensemble **train** pour entraîner le modèle,\n",
    "- un ensemble **test** pour évaluer sa performance sur des données \"inédites\".\n",
    "\n",
    "Nous allons utiliser `train_test_split` de scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 4. Split train/test\n",
    "# ========================================================================\n",
    "X = df[\"cleaned_text\"]  # Features (text)\n",
    "y = df[\"label\"]         # Label (spam ou ham)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Taille du jeu d'entraînement :\", len(X_train))\n",
    "print(\"Taille du jeu de test        :\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Vectorisation TF-IDF\n",
    "\n",
    "Nous allons transformer nos textes en **matrice TF-IDF** via `TfidfVectorizer`.\n",
    "- Ceci va compter la fréquence des mots tout en tenant compte de leur rareté dans l'ensemble du corpus.\n",
    "- La ponctuation, les minuscules, etc. peuvent aussi être gérés directement par le vectorizer (avec les bons arguments).\n",
    "\n",
    "Ensuite, nous entraînerons un classifieur **Naive Bayes** (`MultinomialNB`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 5. Vectorisation et entraînement du modèle\n",
    "# ========================================================================\n",
    "\n",
    "# 5.1. Création du vectorizer TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# 5.2. Ajustement du vectorizer sur le texte d'entraînement et transformation\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# 5.3. Transformation du texte de test\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# 5.4. Entraînement d'un classifieur Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Modèle entraîné avec succès !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Évaluation du modèle\n",
    "\n",
    "Nous allons prédire les labels sur le jeu de test, puis calculer :\n",
    "- l'accuracy,\n",
    "- la matrice de confusion,\n",
    "- le rapport de classification (précision, rappel, F1-score).\n",
    "\n",
    "Cela permet de juger des performances globales et de voir si le modèle confond parfois spam et ham.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 6. Évaluation du modèle\n",
    "# ========================================================================\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy :\", acc)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"spam\", \"ham\"])\n",
    "print(\"Matrice de confusion :\\n\", cm)\n",
    "\n",
    "# Rapport de classification\n",
    "report = classification_report(y_test, y_pred, labels=[\"spam\", \"ham\"])\n",
    "print(\"Rapport de classification :\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de visualiser la matrice de confusion, on peut utiliser seaborn `heatmap`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la matrice de confusion\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"spam\", \"ham\"], yticklabels=[\"spam\", \"ham\"])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vérité terrain\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour **une classification binaire** comme « spam vs ham », la matrice de confusion est un **tableau qui compare les étiquettes réelles** (lignes) aux **étiquettes prédites** (colonnes). Dans l’exemple où on appelle :\n",
    "\n",
    "```python\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"spam\", \"ham\"])\n",
    "```\n",
    "\n",
    "- Les **lignes** correspondent aux **étiquettes réelles** : la première ligne représente les vrais *spam*, la seconde ligne représente les vrais *ham*.  \n",
    "- Les **colonnes** correspondent aux **étiquettes prédites** : la première colonne est « prédit spam », la seconde colonne est « prédit ham ».\n",
    "\n",
    "La matrice `cm` est donc de la forme :\n",
    "\n",
    "```\n",
    "        Prédit = spam    Prédit = ham\n",
    "-------------------------------------\n",
    "Spam |    a (TP)           b (FN)\n",
    "Ham  |    c (FP)           d (TN)\n",
    "```\n",
    "\n",
    "où :\n",
    "\n",
    "1. **a (Top-Left)** : nombre de *spams* (réels) correctement prédits comme *spam*.  \n",
    "   \\- On parle souvent de **True Positives** (TP) pour la classe *spam*.  \n",
    "\n",
    "2. **b (Top-Right)** : nombre de *spams* (réels) mal classés comme *ham*.  \n",
    "   \\- Ce sont les **False Negatives** (FN) : le modèle a « raté » des spams.  \n",
    "\n",
    "3. **c (Bottom-Left)** : nombre de *hams* (réels) mal classés comme *spam*.  \n",
    "   \\- Ce sont les **False Positives** (FP) : le modèle a donné un *faux* spam.  \n",
    "\n",
    "4. **d (Bottom-Right)** : nombre de *hams* (réels) correctement prédits comme *ham*.  \n",
    "   \\- On les appelle **True Negatives** (TN) pour la classe *spam*.  \n",
    "\n",
    "---\n",
    "\n",
    "## Comment l’interpréter ?\n",
    "\n",
    "- **a (TP) élevé** : le modèle détecte bien les spams.\n",
    "- **b (FN) élevé** : trop de spams ne sont pas détectés (risque pour un système de sécurité).\n",
    "- **c (FP) élevé** : trop de hams (messages légitimes) sont classés spam (gène pour l’utilisateur).\n",
    "- **d (TN) élevé** : la plupart des messages légitimes sont reconnus comme tels.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Exemple de lecture concrète\n",
    "\n",
    "Si on obtient une matrice de confusion :\n",
    "\n",
    "```\n",
    "[[ 30   5 ]\n",
    " [  2  40 ]]\n",
    "```\n",
    "\n",
    "en supposant l’ordre (spam, ham) :\n",
    "\n",
    "1. **30** (*row spam, col spam*) : le modèle a correctement classé 30 messages spam en spam (TP).  \n",
    "2. **5**  (*row spam, col ham*) : 5 vrais spam ont été mal classés en ham (FN).  \n",
    "3. **2**  (*row ham, col spam*) : 2 vrais ham ont été mal classés en spam (FP).  \n",
    "4. **40** (*row ham, col ham*) : 40 vrais ham ont été correctement classés en ham (TN).\n",
    "\n",
    "- Rappel pour spam = \\( \\frac{30}{30+5} = 0.857 \\) (85.7% de spams détectés).  \n",
    "- Précision pour spam = \\( \\frac{30}{30+2} = 0.938 \\) (93.8% des messages étiquetés spam sont vraiment spam).  \n",
    "\n",
    "En comparant ces valeurs, vous pouvez juger si votre modèle est acceptable selon vos objectifs (détecter un maximum de spam, minimiser les faux positifs, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## En résumé\n",
    "\n",
    "La **matrice de confusion** permet de **visualiser** où se trompe votre modèle :  \n",
    "- Combien de *spam* le modèle rate (FN)  \n",
    "- Combien de *ham* le modèle étiquette à tort comme spam (FP)  \n",
    "\n",
    "C’est un outil essentiel pour comprendre la **qualité** de la classification et pour orienter les **améliorations** du modèle (par exemple en ajustant les hyperparamètres, le seuil de décision, ou en augmentant la taille/l’équilibre du jeu de données)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Améliorations possibles\n",
    "\n",
    "- **Optimisation des hyperparamètres** :  \n",
    "  Par exemple, on pourrait faire une recherche de paramètres (`GridSearchCV` ou `RandomizedSearchCV`) sur les \n",
    "  paramètres du TF-IDF (ngram_range, min_df, max_df, etc.) ou sur ceux du classifieur (alpha pour le Naive Bayes).\n",
    "\n",
    "- **Pipeline scikit-learn** :  \n",
    "  Pour plus de simplicité, on peut utiliser un `Pipeline` qui enchaîne automatiquement la vectorisation et la classification.\n",
    "\n",
    "- **Prétraitement avancé** :  \n",
    "  - Utiliser la tokenisation NLTK, la suppression de stopwords, la lemmatisation, etc.  \n",
    "  - Gérer les emojis, le vocabulaire spécifique à la cybersécurité, etc.\n",
    "\n",
    "- **Approches avancées** :  \n",
    "  - Autres algorithmes de classification (SVM, Logistic Regression, Random Forest).  \n",
    "  - Intégration de l'apprentissage profond (transformers comme BERT).\n",
    "\n",
    "---\n",
    "# 8. Conclusion\n",
    "\n",
    "Nous avons vu dans ce notebook :\n",
    "1. Comment charger un dataset de messages (spam/ham).\n",
    "2. Appliquer un prétraitement léger.\n",
    "3. Transformer le texte en caractéristiques via TF-IDF.\n",
    "4. Entraîner un modèle Naive Bayes.\n",
    "5. Évaluer la performance sur un jeu de test (accuracy, matrice de confusion, etc.).\n",
    "\n",
    "Ce pipeline de base constitue un point de départ pour de multiples applications de **classification de texte**, \n",
    "notamment la détection de spam, le filtrage d'e-mails malveillants, ou encore la catégorisation de tickets de support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
